{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  $50-75k  \\\n",
      "0            Agnostic     27       34       60       81       76      137   \n",
      "1             Atheist     12       27       37       52       35       70   \n",
      "2            Buddhist     27       21       30       34       33       58   \n",
      "3            Catholic    418      617      732      670      638     1116   \n",
      "4  Don’t know/refused     15       14       15       11       10       35   \n",
      "\n",
      "   $75-100k  $100-150k  >150k  Don't know/refused  \n",
      "0       122        109     84                  96  \n",
      "1        73         59     74                  76  \n",
      "2        62         39     53                  54  \n",
      "3       949        792    633                1489  \n",
      "4        21         17     18                 116  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "pew = pd.read_csv('./data/pew.csv')\n",
    "print(pew.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# melt 메서드\n",
    "column을 row로 바꾸어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  \\\n",
      "0                  Agnostic     27       34       60       81       76   \n",
      "1                   Atheist     12       27       37       52       35   \n",
      "2                  Buddhist     27       21       30       34       33   \n",
      "3                  Catholic    418      617      732      670      638   \n",
      "4        Don’t know/refused     15       14       15       11       10   \n",
      "5          Evangelical Prot    575      869     1064      982      881   \n",
      "6                     Hindu      1        9        7        9       11   \n",
      "7   Historically Black Prot    228      244      236      238      197   \n",
      "8         Jehovah's Witness     20       27       24       24       21   \n",
      "9                    Jewish     19       19       25       25       30   \n",
      "10            Mainline Prot    289      495      619      655      651   \n",
      "11                   Mormon     29       40       48       51       56   \n",
      "12                   Muslim      6        7        9       10        9   \n",
      "13                 Orthodox     13       17       23       32       32   \n",
      "14          Other Christian      9        7       11       13       13   \n",
      "15             Other Faiths     20       33       40       46       49   \n",
      "16    Other World Religions      5        2        3        4        2   \n",
      "17             Unaffiliated    217      299      374      365      341   \n",
      "\n",
      "    $50-75k  $75-100k  $100-150k  >150k  Don't know/refused  \n",
      "0       137       122        109     84                  96  \n",
      "1        70        73         59     74                  76  \n",
      "2        58        62         39     53                  54  \n",
      "3      1116       949        792    633                1489  \n",
      "4        35        21         17     18                 116  \n",
      "5      1486       949        723    414                1529  \n",
      "6        34        47         48     54                  37  \n",
      "7       223       131         81     78                 339  \n",
      "8        30        15         11      6                  37  \n",
      "9        95        69         87    151                 162  \n",
      "10     1107       939        753    634                1328  \n",
      "11      112        85         49     42                  69  \n",
      "12       23        16          8      6                  22  \n",
      "13       47        38         42     46                  73  \n",
      "14       14        18         14     12                  18  \n",
      "15       63        46         40     41                  71  \n",
      "16        7         3          4      4                   8  \n",
      "17      528       407        321    258                 597  \n"
     ]
    }
   ],
   "source": [
    "print(pew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  religion            variable  value\n",
      "0                 Agnostic               <$10k     27\n",
      "1                  Atheist               <$10k     12\n",
      "2                 Buddhist               <$10k     27\n",
      "3                 Catholic               <$10k    418\n",
      "4       Don’t know/refused               <$10k     15\n",
      "..                     ...                 ...    ...\n",
      "175               Orthodox  Don't know/refused     73\n",
      "176        Other Christian  Don't know/refused     18\n",
      "177           Other Faiths  Don't know/refused     71\n",
      "178  Other World Religions  Don't know/refused      8\n",
      "179           Unaffiliated  Don't know/refused    597\n",
      "\n",
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "pew_long = pd.melt(pew, id_vars='religion')\n",
    "print(pew_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  religion              income  count\n",
      "0                 Agnostic               <$10k     27\n",
      "1                  Atheist               <$10k     12\n",
      "2                 Buddhist               <$10k     27\n",
      "3                 Catholic               <$10k    418\n",
      "4       Don’t know/refused               <$10k     15\n",
      "..                     ...                 ...    ...\n",
      "175               Orthodox  Don't know/refused     73\n",
      "176        Other Christian  Don't know/refused     18\n",
      "177           Other Faiths  Don't know/refused     71\n",
      "178  Other World Religions  Don't know/refused      8\n",
      "179           Unaffiliated  Don't know/refused    597\n",
      "\n",
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "## id_var는 안바꾼다 그 내용을 \n",
    "pew_long = pd.melt(pew, id_vars='religion', var_name='income', value_name='count')\n",
    "print(pew_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2개 이상의 열을 고정하고 나머지 열을 행으로 바꾸기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87  82.0   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  \n",
      "0  72.0  77.0  87.0  94.0  99.0   NaN   NaN   NaN   NaN  \n",
      "1  92.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2  68.0  67.0  66.0  57.0  54.0  53.0  51.0  51.0  51.0  \n",
      "3  72.0  69.0  67.0  65.0  55.0  59.0  62.0  61.0  61.0  \n",
      "4  25.0  17.0  17.0  31.0  36.0  49.0  53.0  57.0  64.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "billboard = pd.read_csv('./data/billboard.csv')\n",
    "\n",
    "print(billboard.iloc[0:5, 0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year            artist                    track  time date.entered  \\\n",
      "0      2000             2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   \n",
      "1      2000           2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   \n",
      "2      2000      3 Doors Down               Kryptonite  3:53   2000-04-08   \n",
      "3      2000      3 Doors Down                    Loser  4:24   2000-10-21   \n",
      "4      2000          504 Boyz            Wobble Wobble  3:35   2000-04-15   \n",
      "...     ...               ...                      ...   ...          ...   \n",
      "24087  2000       Yankee Grey     Another Nine Minutes  3:10   2000-04-29   \n",
      "24088  2000  Yearwood, Trisha          Real Live Woman  3:55   2000-04-01   \n",
      "24089  2000   Ying Yang Twins  Whistle While You Tw...  4:19   2000-03-18   \n",
      "24090  2000     Zombie Nation            Kernkraft 400  3:30   2000-09-02   \n",
      "24091  2000   matchbox twenty                     Bent  4:12   2000-04-29   \n",
      "\n",
      "       week  rating  \n",
      "0       wk1    87.0  \n",
      "1       wk1    91.0  \n",
      "2       wk1    81.0  \n",
      "3       wk1    76.0  \n",
      "4       wk1    57.0  \n",
      "...     ...     ...  \n",
      "24087  wk76     NaN  \n",
      "24088  wk76     NaN  \n",
      "24089  wk76     NaN  \n",
      "24090  wk76     NaN  \n",
      "24091  wk76     NaN  \n",
      "\n",
      "[24092 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#id_var는 고정이야 \n",
    "billboard_long = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'],\n",
    "                         var_name='week', value_name='rating')\n",
    "\n",
    "print(billboard_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  Day  Cases_Guinea  Cases_Liberia  Cases_SierraLeone  \\\n",
      "0      1/5/2015  289        2776.0            NaN            10030.0   \n",
      "1      1/4/2015  288        2775.0            NaN             9780.0   \n",
      "2      1/3/2015  287        2769.0         8166.0             9722.0   \n",
      "3      1/2/2015  286           NaN         8157.0                NaN   \n",
      "4    12/31/2014  284        2730.0         8115.0             9633.0   \n",
      "..          ...  ...           ...            ...                ...   \n",
      "117   3/27/2014    5         103.0            8.0                6.0   \n",
      "118   3/26/2014    4          86.0            NaN                NaN   \n",
      "119   3/25/2014    3          86.0            NaN                NaN   \n",
      "120   3/24/2014    2          86.0            NaN                NaN   \n",
      "121   3/22/2014    0          49.0            NaN                NaN   \n",
      "\n",
      "     Cases_Nigeria  Cases_Senegal  Cases_UnitedStates  Cases_Spain  \\\n",
      "0              NaN            NaN                 NaN          NaN   \n",
      "1              NaN            NaN                 NaN          NaN   \n",
      "2              NaN            NaN                 NaN          NaN   \n",
      "3              NaN            NaN                 NaN          NaN   \n",
      "4              NaN            NaN                 NaN          NaN   \n",
      "..             ...            ...                 ...          ...   \n",
      "117            NaN            NaN                 NaN          NaN   \n",
      "118            NaN            NaN                 NaN          NaN   \n",
      "119            NaN            NaN                 NaN          NaN   \n",
      "120            NaN            NaN                 NaN          NaN   \n",
      "121            NaN            NaN                 NaN          NaN   \n",
      "\n",
      "     Cases_Mali  Deaths_Guinea  Deaths_Liberia  Deaths_SierraLeone  \\\n",
      "0           NaN         1786.0             NaN              2977.0   \n",
      "1           NaN         1781.0             NaN              2943.0   \n",
      "2           NaN         1767.0          3496.0              2915.0   \n",
      "3           NaN            NaN          3496.0                 NaN   \n",
      "4           NaN         1739.0          3471.0              2827.0   \n",
      "..          ...            ...             ...                 ...   \n",
      "117         NaN           66.0             6.0                 5.0   \n",
      "118         NaN           62.0             NaN                 NaN   \n",
      "119         NaN           60.0             NaN                 NaN   \n",
      "120         NaN           59.0             NaN                 NaN   \n",
      "121         NaN           29.0             NaN                 NaN   \n",
      "\n",
      "     Deaths_Nigeria  Deaths_Senegal  Deaths_UnitedStates  Deaths_Spain  \\\n",
      "0               NaN             NaN                  NaN           NaN   \n",
      "1               NaN             NaN                  NaN           NaN   \n",
      "2               NaN             NaN                  NaN           NaN   \n",
      "3               NaN             NaN                  NaN           NaN   \n",
      "4               NaN             NaN                  NaN           NaN   \n",
      "..              ...             ...                  ...           ...   \n",
      "117             NaN             NaN                  NaN           NaN   \n",
      "118             NaN             NaN                  NaN           NaN   \n",
      "119             NaN             NaN                  NaN           NaN   \n",
      "120             NaN             NaN                  NaN           NaN   \n",
      "121             NaN             NaN                  NaN           NaN   \n",
      "\n",
      "     Deaths_Mali  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n",
      "..           ...  \n",
      "117          NaN  \n",
      "118          NaN  \n",
      "119          NaN  \n",
      "120          NaN  \n",
      "121          NaN  \n",
      "\n",
      "[122 rows x 18 columns]\n",
      "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
      "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
      "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
      "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
      "       'Deaths_Spain', 'Deaths_Mali'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## 에볼라 데이터 \n",
    "\n",
    "ebola = pd.read_csv('./data/country_timeseries.csv')\n",
    "print(ebola)\n",
    "print(ebola.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Day      variable   value\n",
      "0       1/5/2015  289  Cases_Guinea  2776.0\n",
      "1       1/4/2015  288  Cases_Guinea  2775.0\n",
      "2       1/3/2015  287  Cases_Guinea  2769.0\n",
      "3       1/2/2015  286  Cases_Guinea     NaN\n",
      "4     12/31/2014  284  Cases_Guinea  2730.0\n",
      "...          ...  ...           ...     ...\n",
      "1947   3/27/2014    5   Deaths_Mali     NaN\n",
      "1948   3/26/2014    4   Deaths_Mali     NaN\n",
      "1949   3/25/2014    3   Deaths_Mali     NaN\n",
      "1950   3/24/2014    2   Deaths_Mali     NaN\n",
      "1951   3/22/2014    0   Deaths_Mali     NaN\n",
      "\n",
      "[1952 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "## id_vars에 보고 싶은 내용들만 적는다 \n",
    "## 그럼 그 내용들을 행으로 두고 나머진 열로 들어간다. \n",
    "ebola_long = pd.melt(ebola, id_vars=['Date', 'Day'])\n",
    "print(ebola_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 열 이름 분리하고 데이터프레임에 추가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [Cases, Guinea]\n",
      "1       [Cases, Guinea]\n",
      "2       [Cases, Guinea]\n",
      "3       [Cases, Guinea]\n",
      "4       [Cases, Guinea]\n",
      "             ...       \n",
      "1947     [Deaths, Mali]\n",
      "1948     [Deaths, Mali]\n",
      "1949     [Deaths, Mali]\n",
      "1950     [Deaths, Mali]\n",
      "1951     [Deaths, Mali]\n",
      "Name: variable, Length: 1952, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "## variable이라는 변수에 str이라는 클래스를 가지고 스플릿이라는 매소드를 적용 \n",
    "## 리스트로 출력이 나온다. \n",
    "variable_split = ebola_long.variable.str.split('_')\n",
    "print(variable_split)\n",
    "print(type(variable_split))\n",
    "print(type(variable_split[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "status_values = variable_split.str.get(0) \n",
    "country_values = variable_split.str.get(1)\n",
    "\n",
    "ebola_long['status'] = status_values \n",
    "ebola_long['country'] = country_values\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat 메서드를 응용하여 데이터프레임에 열 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "## expand 데이터프레임 형식으로 생성됨 \n",
    "\n",
    "variable_split = ebola_long.variable.str.split('_', expand=True) \n",
    "variable_split.columns = ['status', 'country'] \n",
    "ebola_parsed = pd.concat([ebola_long, variable_split], axis=1) ## 옆에 붙여라!\n",
    "\n",
    "print(ebola_parsed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pivot \n",
    " row를 column으로 바꾼다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element  d1    d2    d3  d4    d5  d6  d7\n",
      "0  MX17004  2010      1    tmax NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "1  MX17004  2010      1    tmin NaN   NaN   NaN NaN   NaN NaN NaN\n",
      "2  MX17004  2010      2    tmax NaN  27.3  24.1 NaN   NaN NaN NaN\n",
      "3  MX17004  2010      2    tmin NaN  14.4  14.4 NaN   NaN NaN NaN\n",
      "4  MX17004  2010      3    tmax NaN   NaN   NaN NaN  32.1 NaN NaN\n",
      "         id  year  month element    d1    d2    d3    d4    d5    d6  ...  \\\n",
      "0   MX17004  2010      1    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "1   MX17004  2010      1    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "2   MX17004  2010      2    tmax   NaN  27.3  24.1   NaN   NaN   NaN  ...   \n",
      "3   MX17004  2010      2    tmin   NaN  14.4  14.4   NaN   NaN   NaN  ...   \n",
      "4   MX17004  2010      3    tmax   NaN   NaN   NaN   NaN  32.1   NaN  ...   \n",
      "5   MX17004  2010      3    tmin   NaN   NaN   NaN   NaN  14.2   NaN  ...   \n",
      "6   MX17004  2010      4    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "7   MX17004  2010      4    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "8   MX17004  2010      5    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "9   MX17004  2010      5    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "10  MX17004  2010      6    tmax   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "11  MX17004  2010      6    tmin   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "12  MX17004  2010      7    tmax   NaN   NaN  28.6   NaN   NaN   NaN  ...   \n",
      "13  MX17004  2010      7    tmin   NaN   NaN  17.5   NaN   NaN   NaN  ...   \n",
      "14  MX17004  2010      8    tmax   NaN   NaN   NaN   NaN  29.6   NaN  ...   \n",
      "15  MX17004  2010      8    tmin   NaN   NaN   NaN   NaN  15.8   NaN  ...   \n",
      "16  MX17004  2010     10    tmax   NaN   NaN   NaN   NaN  27.0   NaN  ...   \n",
      "17  MX17004  2010     10    tmin   NaN   NaN   NaN   NaN  14.0   NaN  ...   \n",
      "18  MX17004  2010     11    tmax   NaN  31.3   NaN  27.2  26.3   NaN  ...   \n",
      "19  MX17004  2010     11    tmin   NaN  16.3   NaN  12.0   7.9   NaN  ...   \n",
      "20  MX17004  2010     12    tmax  29.9   NaN   NaN   NaN   NaN  27.8  ...   \n",
      "21  MX17004  2010     12    tmin  13.8   NaN   NaN   NaN   NaN  10.5  ...   \n",
      "\n",
      "    d22   d23  d24   d25   d26   d27   d28   d29   d30   d31  \n",
      "0   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN  27.8   NaN  \n",
      "1   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN  14.5   NaN  \n",
      "2   NaN  29.9  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "3   NaN  10.7  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "4   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "5   NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "6   NaN   NaN  NaN   NaN   NaN  36.3   NaN   NaN   NaN   NaN  \n",
      "7   NaN   NaN  NaN   NaN   NaN  16.7   NaN   NaN   NaN   NaN  \n",
      "8   NaN   NaN  NaN   NaN   NaN  33.2   NaN   NaN   NaN   NaN  \n",
      "9   NaN   NaN  NaN   NaN   NaN  18.2   NaN   NaN   NaN   NaN  \n",
      "10  NaN   NaN  NaN   NaN   NaN   NaN   NaN  30.1   NaN   NaN  \n",
      "11  NaN   NaN  NaN   NaN   NaN   NaN   NaN  18.0   NaN   NaN  \n",
      "12  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "13  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "14  NaN  26.4  NaN  29.7   NaN   NaN   NaN  28.0   NaN  25.4  \n",
      "15  NaN  15.0  NaN  15.6   NaN   NaN   NaN  15.3   NaN  15.4  \n",
      "16  NaN   NaN  NaN   NaN   NaN   NaN  31.2   NaN   NaN   NaN  \n",
      "17  NaN   NaN  NaN   NaN   NaN   NaN  15.0   NaN   NaN   NaN  \n",
      "18  NaN   NaN  NaN   NaN  28.1  27.7   NaN   NaN   NaN   NaN  \n",
      "19  NaN   NaN  NaN   NaN  12.1  14.2   NaN   NaN   NaN   NaN  \n",
      "20  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "21  NaN   NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[22 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weather = pd.read_csv('./data/weather.csv') \n",
    "print(weather.iloc[:5, :11])\n",
    "print(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element day  temp\n",
      "0  MX17004  2010      1    tmax  d1   NaN\n",
      "1  MX17004  2010      1    tmin  d1   NaN\n",
      "2  MX17004  2010      2    tmax  d1   NaN\n",
      "3  MX17004  2010      2    tmin  d1   NaN\n",
      "4  MX17004  2010      3    tmax  d1   NaN\n"
     ]
    }
   ],
   "source": [
    "weather_melt = pd.melt(weather, id_vars=['id', 'year', 'month', 'element'],\n",
    "                       var_name='day', value_name='temp') \n",
    "print(weather_melt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element                 tmax  tmin\n",
      "id      year month day            \n",
      "MX17004 2010 1     d30  27.8  14.5\n",
      "             2     d11  29.7  13.4\n",
      "                   d2   27.3  14.4\n",
      "                   d23  29.9  10.7\n",
      "                   d3   24.1  14.4\n",
      "             3     d10  34.5  16.8\n",
      "                   d16  31.1  17.6\n",
      "                   d5   32.1  14.2\n",
      "             4     d27  36.3  16.7\n",
      "             5     d27  33.2  18.2\n",
      "             6     d17  28.0  17.5\n",
      "                   d29  30.1  18.0\n",
      "             7     d3   28.6  17.5\n",
      "                   d14  29.9  16.5\n",
      "             8     d23  26.4  15.0\n",
      "                   d5   29.6  15.8\n",
      "                   d29  28.0  15.3\n",
      "                   d13  29.8  16.5\n",
      "                   d25  29.7  15.6\n",
      "                   d31  25.4  15.4\n",
      "                   d8   29.0  17.3\n",
      "             10    d5   27.0  14.0\n",
      "                   d14  29.5  13.0\n",
      "                   d15  28.7  10.5\n",
      "                   d28  31.2  15.0\n",
      "                   d7   28.1  12.9\n",
      "             11    d2   31.3  16.3\n",
      "                   d5   26.3   7.9\n",
      "                   d27  27.7  14.2\n",
      "                   d26  28.1  12.1\n",
      "                   d4   27.2  12.0\n",
      "             12    d1   29.9  13.8\n",
      "                   d6   27.8  10.5\n"
     ]
    }
   ],
   "source": [
    "## element를 올리겠다 element에 있는 항목을 행으로 만들겠다.\n",
    "## element 행에 있는 temp 값을 넣겠따\n",
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=['id', 'year', 'month', 'day'], \n",
    "    columns='element', \n",
    "    values='temp'\n",
    ")\n",
    "\n",
    "print(weather_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빌보드 차트의 중복 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 7)\n",
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "billboard = pd.read_csv('./data/billboard.csv')\n",
    "billboard_long = pd.melt(billboard, id_vars=['year', 'artist', 'track', 'time', 'date.entered'], var_name='week', value_name='rating')\n",
    "\n",
    "print(billboard_long.shape)\n",
    "\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year        artist  track  time date.entered week  rating\n",
      "3     2000  3 Doors Down  Loser  4:24   2000-10-21  wk1    76.0\n",
      "320   2000  3 Doors Down  Loser  4:24   2000-10-21  wk2    76.0\n",
      "637   2000  3 Doors Down  Loser  4:24   2000-10-21  wk3    72.0\n",
      "954   2000  3 Doors Down  Loser  4:24   2000-10-21  wk4    69.0\n",
      "1271  2000  3 Doors Down  Loser  4:24   2000-10-21  wk5    67.0\n",
      "(317, 4)\n",
      "     year            artist                    track  time\n",
      "0    2000             2 Pac  Baby Don't Cry (Keep...  4:22\n",
      "1    2000           2Ge+her  The Hardest Part Of ...  3:15\n",
      "2    2000      3 Doors Down               Kryptonite  3:53\n",
      "3    2000      3 Doors Down                    Loser  4:24\n",
      "4    2000          504 Boyz            Wobble Wobble  3:35\n",
      "..    ...               ...                      ...   ...\n",
      "312  2000       Yankee Grey     Another Nine Minutes  3:10\n",
      "313  2000  Yearwood, Trisha          Real Live Woman  3:55\n",
      "314  2000   Ying Yang Twins  Whistle While You Tw...  4:19\n",
      "315  2000     Zombie Nation            Kernkraft 400  3:30\n",
      "316  2000   matchbox twenty                     Bent  4:12\n",
      "\n",
      "[317 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "## drop_duplicates 메소드를 이용하면 중복되는 항목들이 지워진다.ㅏ \n",
    "print(billboard_long[billboard_long.track == 'Loser'].head())\n",
    "\n",
    "billboard_songs = billboard_long[['year', 'artist', 'track', 'time']] \n",
    "billboard_songs = billboard_songs.drop_duplicates() \n",
    "print(billboard_songs.shape)\n",
    "print(billboard_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year          artist                    track  time  id\n",
      "0  2000           2 Pac  Baby Don't Cry (Keep...  4:22   0\n",
      "1  2000         2Ge+her  The Hardest Part Of ...  3:15   1\n",
      "2  2000    3 Doors Down               Kryptonite  3:53   2\n",
      "3  2000    3 Doors Down                    Loser  4:24   3\n",
      "4  2000        504 Boyz            Wobble Wobble  3:35   4\n",
      "5  2000            98^0  Give Me Just One Nig...  3:24   5\n",
      "6  2000         A*Teens            Dancing Queen  3:44   6\n",
      "7  2000         Aaliyah            I Don't Wanna  4:15   7\n",
      "8  2000         Aaliyah                Try Again  4:03   8\n",
      "9  2000  Adams, Yolanda            Open My Heart  5:30   9\n"
     ]
    }
   ],
   "source": [
    "## id 항목을 새로 추가한다.\n",
    "billboard_songs['id'] = range(len(billboard_songs)) \n",
    "print(billboard_songs.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 8)\n"
     ]
    }
   ],
   "source": [
    "## 원래 파일에 새로 추가 \n",
    "billboard_ratings = billboard_long.merge( billboard_songs, \n",
    "                                         on=['year', 'artist', 'track', 'time']) \n",
    "print(billboard_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-03.csv\n",
      "\n",
      "./data/fhv_tripdata_2015-03.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-04.csv\n",
      "\n",
      "./data/fhv_tripdata_2015-04.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-05.csv\n",
      "\n",
      "./data/fhv_tripdata_2015-05.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os \n",
    "import urllib.request\n",
    "\n",
    "# 네트워크 상태에 따라 5 ~ 15분이 소요됩니다.\n",
    "with open('./data/raw_data_urls.txt', 'r') as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5:\n",
    "            break \n",
    "        fn = url.split('/')[-1].strip()\n",
    "        fp = os.path.join('', './data', fn)\n",
    "        print(url)\n",
    "        print(fp)\n",
    "        urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/fhv_tripdata_2015-04.csv', './data/fhv_tripdata_2015-05.csv', './data/fhv_tripdata_2015-03.csv', './data/fhv_tripdata_2015-01.csv', './data/fhv_tripdata_2015-02.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "nyc_taxi_data = glob.glob('./data/fhv_*') \n",
    "print(nyc_taxi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi1 = pd.read_csv(nyc_taxi_data[0]) \n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1]) \n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2]) \n",
    "taxi4 = pd.read_csv(nyc_taxi_data[3]) \n",
    "taxi5 = pd.read_csv(nyc_taxi_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-04-01 04:30:00         NaN\n",
      "1               B00001  2015-04-01 06:00:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-05-01 04:30:00         NaN\n",
      "1               B00001  2015-05-01 05:00:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00029  2015-03-01 00:02:00       213.0\n",
      "1               B00029  2015-03-01 00:03:00        51.0\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-01-01 00:30:00         NaN\n",
      "1               B00013  2015-01-01 01:22:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-02-01 00:00:00         NaN\n",
      "1               B00013  2015-02-01 00:01:00         NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(taxi1.head(n=2)) \n",
    "print(taxi2.head(n=2)) \n",
    "print(taxi3.head(n=2)) \n",
    "print(taxi4.head(n=2)) \n",
    "print(taxi5.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3917789, 3)\n",
      "(4296067, 3)\n",
      "(3281427, 3)\n",
      "(2746033, 3)\n",
      "(3126401, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(taxi1.shape) \n",
    "print(taxi2.shape) \n",
    "print(taxi3.shape) \n",
    "print(taxi4.shape) \n",
    "print(taxi5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17367717, 3)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "taxi = pd.concat([taxi1, taxi2, taxi3, taxi4, taxi5])\n",
    "print(taxi.shape)\n",
    "\n",
    "\n",
    "\n",
    "list_taxi_df = [] \n",
    "for csv_filename in nyc_taxi_data:\n",
    "    # print(csv_filename)\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    list_taxi_df.append(df) \n",
    "\n",
    "print(len(list_taxi_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 잘못 입력한 문자열 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     total_bill   tip     sex smoker   day    time  size\n",
      "0         16.99  1.01  Female     No   Sun  Dinner     2\n",
      "1         10.34  1.66    Male     No   Sun  Dinner     3\n",
      "2         21.01  3.50    Male     No   Sun  Dinner     3\n",
      "3         23.68  3.31    Male     No   Sun  Dinner     2\n",
      "4         24.59  3.61  Female     No   Sun  Dinner     4\n",
      "..          ...   ...     ...    ...   ...     ...   ...\n",
      "239       29.03  5.92    Male     No   Sat  Dinner     3\n",
      "240       27.18  2.00  Female    Yes   Sat  Dinner     2\n",
      "241       22.67  2.00    Male    Yes   Sat  Dinner     2\n",
      "242       17.82  1.75    Male     No   Sat  Dinner     2\n",
      "243       18.78  3.00  Female     No  Thur  Dinner     2\n",
      "\n",
      "[244 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "print(tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_bill     float64\n",
      "tip            float64\n",
      "sex           category\n",
      "smoker        category\n",
      "day           category\n",
      "time          category\n",
      "size             int64\n",
      "sex_str         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## astype 속성을 바꾼다. \n",
    "tips['sex_str'] = tips['sex'].astype(str)\n",
    "print(tips.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  total_bill   tip     sex smoker  day    time  size sex_str\n",
      "0      16.99  1.01  Female     No  Sun  Dinner     2  Female\n",
      "1    missing  1.66    Male     No  Sun  Dinner     3    Male\n",
      "2      21.01  3.50    Male     No  Sun  Dinner     3    Male\n",
      "3    missing  3.31    Male     No  Sun  Dinner     2    Male\n",
      "4      24.59  3.61  Female     No  Sun  Dinner     4  Female\n",
      "5    missing  4.71    Male     No  Sun  Dinner     4    Male\n",
      "6       8.77  2.00    Male     No  Sun  Dinner     2    Male\n",
      "7    missing  3.12    Male     No  Sun  Dinner     4    Male\n",
      "8      15.04  1.96    Male     No  Sun  Dinner     2    Male\n",
      "9      14.78  3.23    Male     No  Sun  Dinner     2    Male\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tips_sub_miss = tips.head(10)\n",
    "tips_sub_miss.loc[[1, 3, 5, 7], 'total_bill'] = 'missing'\n",
    "\n",
    "print(tips_sub_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_bill      object\n",
      "tip            float64\n",
      "sex           category\n",
      "smoker        category\n",
      "day           category\n",
      "time          category\n",
      "size             int64\n",
      "sex_str         object\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'missing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-c79622eeca79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtips_sub_miss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtips_sub_miss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_bill'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## => 에러가 발생한다.ㅏ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5880\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5881\u001b[0m             new_data = self._data.astype(\n\u001b[0;32m-> 5882\u001b[0;31m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5883\u001b[0m             )\n\u001b[1;32m   5884\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_astype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_astype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                     \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mvals1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'missing'"
     ]
    }
   ],
   "source": [
    "print(tips_sub_miss.dtypes)\n",
    "\n",
    "tips_sub_miss['total_bill'].astype(float) ## => 에러가 발생한다.ㅏ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_bill      object\n",
      "tip            float64\n",
      "sex           category\n",
      "smoker        category\n",
      "day           category\n",
      "time          category\n",
      "size             int64\n",
      "sex_str         object\n",
      "dtype: object\n",
      "total_bill      object\n",
      "tip            float64\n",
      "sex           category\n",
      "smoker        category\n",
      "day           category\n",
      "time          category\n",
      "size             int64\n",
      "sex_str         object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(tips_sub_miss.dtypes)\n",
    "\n",
    "##########################################################\n",
    "## to_numerinc\n",
    "## 에러가 발생하면 무시해라 !! 대신 데이터가 바뀌지 않는다 . \n",
    "tips_sub_miss['total_bill'] = pd.to_numeric( tips_sub_miss['total_bill'], errors='ignore')\n",
    "\n",
    "print(tips_sub_miss.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_bill     float64\n",
      "tip            float64\n",
      "sex           category\n",
      "smoker        category\n",
      "day           category\n",
      "time          category\n",
      "size             int64\n",
      "sex_str         object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## 컬럼의 타입이 변형 된다. \n",
    "tips_sub_miss['total_bill'] = pd.to_numeric( tips_sub_miss['total_bill'], errors='coerce')\n",
    "\n",
    "print(tips_sub_miss.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_bill     float32\n",
      "tip            float64\n",
      "sex           category\n",
      "smoker        category\n",
      "day           category\n",
      "time          category\n",
      "size             int64\n",
      "sex_str         object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "## 'downcast' => 데이터 사이즈를 바꿀 수 있다. \n",
    "tips_sub_miss['total_bill'] = pd.to_numeric( tips_sub_miss['total_bill'], \n",
    "                                            errors='coerce', downcast='float')\n",
    "\n",
    "print(tips_sub_miss.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문자열을 카테고리로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 8 columns):\n",
      "total_bill    244 non-null float64\n",
      "tip           244 non-null float64\n",
      "sex           244 non-null object\n",
      "smoker        244 non-null category\n",
      "day           244 non-null category\n",
      "time          244 non-null category\n",
      "size          244 non-null int64\n",
      "sex_str       244 non-null object\n",
      "dtypes: category(3), float64(2), int64(1), object(2)\n",
      "memory usage: 10.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tips['sex'] = tips['sex'].astype('str') \n",
    "print(tips.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 8 columns):\n",
      "total_bill    244 non-null float64\n",
      "tip           244 non-null float64\n",
      "sex           244 non-null category\n",
      "smoker        244 non-null category\n",
      "day           244 non-null category\n",
      "time          244 non-null category\n",
      "size          244 non-null int64\n",
      "sex_str       244 non-null object\n",
      "dtypes: category(4), float64(2), int64(1), object(1)\n",
      "memory usage: 9.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tips['sex'] = tips['sex'].astype('category') \n",
    "print(tips.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문자열 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g\n"
     ]
    }
   ],
   "source": [
    "word = 'grail'\n",
    "sent = 'a scratch'\n",
    "\n",
    "print(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40°/46'/52.837\"/N/73°/58'/26.302\"/W\n"
     ]
    }
   ],
   "source": [
    "# join 메서드 \n",
    "d1 = '40°' \n",
    "m1 = \"46'\" \n",
    "s1 = '52.837\"' \n",
    "u1 = 'N'\n",
    "\n",
    "d2 = '73°' \n",
    "m2 = \"58'\" \n",
    "s2 = '26.302\"' \n",
    "u2 = 'W'\n",
    "\n",
    "\n",
    "coords = '/'.join([d1, m1, s1, u1, d2, m2, s2, u2])\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitlines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guard: What? Ridden on a horse?\n",
      "King Arthur: Yes!\n",
      "Guard: You're using coconuts!\n",
      "King Arthur: What?\n",
      "Guard: You've got ... coconut[s] and you're bangin' 'em together. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_str = \"\"\"Guard: What? Ridden on a horse?\n",
    "King Arthur: Yes!\n",
    "Guard: You're using coconuts!\n",
    "King Arthur: What?\n",
    "Guard: You've got ... coconut[s] and you're bangin' 'em together. \n",
    "\"\"\"\n",
    "print(multi_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Guard: What? Ridden on a horse?', 'King Arthur: Yes!', \"Guard: You're using coconuts!\", 'King Arthur: What?', \"Guard: You've got ... coconut[s] and you're bangin' 'em together. \"]\n"
     ]
    }
   ],
   "source": [
    "## splitlines => 한줄씩 읽는거 \n",
    "multi_str_split = multi_str.splitlines() \n",
    "print(multi_str_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What? Ridden on a horse?', \"You're using coconuts!\", \"You've got ... coconut[s] and you're bangin' 'em together. \"]\n"
     ]
    }
   ],
   "source": [
    "## replace\n",
    "guard = multi_str.replace(\"Guard: \", \"\").splitlines()[::2] \n",
    "print(guard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문자열 포매팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's just a flesh wound!\n"
     ]
    }
   ],
   "source": [
    "var = 'flesh wound' \n",
    "s = \"It's just a {}!\"\n",
    "\n",
    "print(s.format(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I only know 7 digits of pi\n"
     ]
    }
   ],
   "source": [
    "## %연산자로 포매팅\n",
    "\n",
    "s = 'I only know %d digits of pi' % 7 \n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hayden Planetarium Coordinates: 40.7815°N, 73.9733°W\n"
     ]
    }
   ],
   "source": [
    "lat='40.7815°N' \n",
    "lon='73.9733°W' \n",
    "s = f'Hayden Planetarium Coordinates: {lat}, {lon}' \n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규식으로 전화번호 패턴 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 're.Match'>\n",
      "<re.Match object; span=(0, 10), match='1234567890'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tele_num = '1234567890'\n",
    "\n",
    "m = re.match(pattern='\\d\\d\\d\\d\\d\\d\\d\\d\\d\\d', string=tele_num) \n",
    "print(type(m))\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시리즈와 데이터프레임에 apply 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b\n",
      "0  10  20\n",
      "1  20  30\n",
      "2  30  40\n"
     ]
    }
   ],
   "source": [
    "### APPLY를 이용하면 함수를 데이터프레임 모든 곳에 넣을 수 있음 \n",
    "def my_sq(x):\n",
    "    return x ** 2\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [10, 20, 30], 'b': [20, 30, 40]}) \n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a     b\n",
      "0  100   400\n",
      "1  400   900\n",
      "2  900  1600\n"
     ]
    }
   ],
   "source": [
    "sq = df[['a','b']].apply(my_sq) \n",
    "print(sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 프레임의 누락값 처리하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "\n",
    "titanic = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "survived       891 non-null int64\n",
      "pclass         891 non-null int64\n",
      "sex            891 non-null object\n",
      "age            714 non-null float64\n",
      "sibsp          891 non-null int64\n",
      "parch          891 non-null int64\n",
      "fare           891 non-null float64\n",
      "embarked       889 non-null object\n",
      "class          891 non-null category\n",
      "who            891 non-null object\n",
      "adult_male     891 non-null bool\n",
      "deck           203 non-null category\n",
      "embark_town    889 non-null object\n",
      "alive          891 non-null object\n",
      "alone          891 non-null bool\n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(titanic.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_missing(vec):\n",
    "    null_vec = pd.isnull(vec)\n",
    "    null_count = np.sum(null_vec)\n",
    "    return null_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#없는 데이터를 찾는다 \n",
    "cmis_col = titanic.apply(count_missing)\n",
    "print(cmis_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 누락데이터 비율 찾기\n",
    "def prop_missing(vec):\n",
    "    num = count_missing(vec)\n",
    "    dem = vec.size\n",
    "    return num / dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived       0.000000\n",
      "pclass         0.000000\n",
      "sex            0.000000\n",
      "age            0.198653\n",
      "sibsp          0.000000\n",
      "parch          0.000000\n",
      "fare           0.000000\n",
      "embarked       0.002245\n",
      "class          0.000000\n",
      "who            0.000000\n",
      "adult_male     0.000000\n",
      "deck           0.772166\n",
      "embark_town    0.002245\n",
      "alive          0.000000\n",
      "alone          0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## 누락 비율로 알아본다.\n",
    "pmis_col = titanic.apply(prop_missing)\n",
    "print(pmis_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_complete(vec):\n",
    "    return 1 - prop_missing(vec)\n",
    "\n",
    "#위의 세개 함수들을 각각 적용\n",
    "cmis_row = titanic.apply(count_missing, axis=1)\n",
    "pmis_row = titanic.apply(prop_missing, axis=1)\n",
    "pcom_row = titanic.apply(prop_complete, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(cmis_row.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.066667\n",
      "1    0.000000\n",
      "2    0.066667\n",
      "3    0.000000\n",
      "4    0.066667\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pmis_row.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.933333\n",
      "1    1.000000\n",
      "2    0.933333\n",
      "3    1.000000\n",
      "4    0.933333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pcom_row.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  num_missing  \n",
      "0    man        True  NaN  Southampton    no  False            1  \n",
      "1  woman       False    C    Cherbourg   yes  False            0  \n",
      "2  woman       False  NaN  Southampton   yes   True            1  \n",
      "3  woman       False    C  Southampton   yes  False            0  \n",
      "4    man        True  NaN  Southampton    no   True            1  \n"
     ]
    }
   ],
   "source": [
    "#누락 값의 종류를 새로운 항으로 삽입\n",
    "titanic['num_missing'] = titanic.apply(count_missing, axis=1)\n",
    "\n",
    "print(titanic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived  pclass     sex  age  sibsp  parch      fare embarked   class  \\\n",
      "629         0       3    male  NaN      0      0    7.7333        Q   Third   \n",
      "428         0       3    male  NaN      0      0    7.7500        Q   Third   \n",
      "181         0       2    male  NaN      0      0   15.0500        C  Second   \n",
      "354         0       3    male  NaN      0      0    7.2250        C   Third   \n",
      "301         1       3    male  NaN      2      0   23.2500        Q   Third   \n",
      "28          1       3  female  NaN      0      0    7.8792        Q   Third   \n",
      "306         1       1  female  NaN      0      0  110.8833        C   First   \n",
      "643         1       3    male  NaN      0      0   56.4958        S   Third   \n",
      "573         1       3  female  NaN      0      0    7.7500        Q   Third   \n",
      "260         0       3    male  NaN      0      0    7.7500        Q   Third   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  num_missing  \n",
      "629    man        True  NaN   Queenstown    no   True            2  \n",
      "428    man        True  NaN   Queenstown    no   True            2  \n",
      "181    man        True  NaN    Cherbourg    no   True            2  \n",
      "354    man        True  NaN    Cherbourg    no   True            2  \n",
      "301    man        True  NaN   Queenstown   yes  False            2  \n",
      "28   woman       False  NaN   Queenstown   yes   True            2  \n",
      "306  woman       False  NaN    Cherbourg   yes   True            2  \n",
      "643    man        True  NaN  Southampton   yes   True            2  \n",
      "573  woman       False  NaN   Queenstown   yes   True            2  \n",
      "260    man        True  NaN   Queenstown    no   True            2  \n"
     ]
    }
   ],
   "source": [
    "# 누락값이 1개 이상인 항들만 뽑아서 10개만 \n",
    "print(titanic.loc[titanic.num_missing > 1, :].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# groupby 메서드로 평균값 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## groupby 여러줄을 하나로 묶는다. \n",
    "import pandas as pd \n",
    "df = pd.read_csv('./data/gapminder.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "1952    49.057620\n",
      "1957    51.507401\n",
      "1962    53.609249\n",
      "1967    55.678290\n",
      "1972    57.647386\n",
      "1977    59.570157\n",
      "1982    61.533197\n",
      "1987    63.212613\n",
      "1992    64.160338\n",
      "1997    65.014676\n",
      "2002    65.694923\n",
      "2007    67.007423\n",
      "Name: lifeExp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "avg_life_exp_by_year = df.groupby('year').lifeExp.mean() \n",
    "print(avg_life_exp_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 2002 2007]\n",
      "49.057619718309866\n",
      "        country continent  year  lifeExp       pop    gdpPercap\n",
      "0   Afghanistan      Asia  1952   28.801   8425333   779.445314\n",
      "12      Albania    Europe  1952   55.230   1282697  1601.056136\n",
      "24      Algeria    Africa  1952   43.077   9279525  2449.008185\n",
      "36       Angola    Africa  1952   30.015   4232095  3520.610273\n",
      "48    Argentina  Americas  1952   62.485  17876956  5911.315053\n"
     ]
    }
   ],
   "source": [
    "years = df.year.unique() \n",
    "print(years)\n",
    "\n",
    "y1952 = df.loc[df.year == 1952, :] \n",
    "y1952_mean = y1952.lifeExp.mean() \n",
    "print(y1952_mean)\n",
    "print(y1952.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 그룹바이가 안 먹힐때 경우를 나눠 각각 계산해서 값을 추가해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.50740112676056\n",
      "53.609249014084504\n",
      "67.00742253521126\n",
      "   year           \n",
      "0  1952  49.057620\n",
      "1  1957  51.507401\n",
      "2  1962  53.609249\n",
      "3  2007  67.007423\n"
     ]
    }
   ],
   "source": [
    "## 그룹바이가 안 먹힐때 각각 계산해서 값을 추가해야 한다. \n",
    "\n",
    "y1957 = df.loc[df.year == 1957, :] \n",
    "y1957_mean = y1957.lifeExp.mean( )\n",
    "print(y1957_mean)\n",
    "\n",
    "y1962 = df.loc[df.year == 1962, :] \n",
    "y1962_mean = y1962.lifeExp.mean( )\n",
    "print(y1962_mean)\n",
    "\n",
    "y2007 = df.loc[df.year == 2007, :] \n",
    "y2007_mean = y2007.lifeExp.mean( )\n",
    "print(y2007_mean)\n",
    "\n",
    "######################################\n",
    "\n",
    "df2 = pd.DataFrame({\"year\":[1952, 1957, 1962, 2007], \n",
    "                    \"\":[y1952_mean, y1957_mean,y1962_mean,y2007_mean]}) \n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 평균값을 구하는 사용자 함수를 groupby 메서드에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_mean(values):\n",
    "    n = len(values)\n",
    "    \n",
    "    sum = 0 \n",
    "    for value in values:\n",
    "        sum += value\n",
    "    \n",
    "    return sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "1952    49.057620\n",
      "1957    51.507401\n",
      "1962    53.609249\n",
      "1967    55.678290\n",
      "1972    57.647386\n",
      "1977    59.570157\n",
      "1982    61.533197\n",
      "1987    63.212613\n",
      "1992    64.160338\n",
      "1997    65.014676\n",
      "2002    65.694923\n",
      "2007    67.007423\n",
      "Name: lifeExp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## 함수를 만들어서 apply처럼 수행\n",
    "## agg 메소드\n",
    "agg_my_mean = df.groupby('year').lifeExp.agg(my_mean) \n",
    "print(agg_my_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 두 개의 인잣값을 받아 처리하는 사용자 함수와 groupby 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_mean_diff(values, diff_value):\n",
    "    n = len(values) \n",
    "    sum = 0 \n",
    "    for value in values:\n",
    "        sum += value \n",
    "    mean = sum / n \n",
    "    return mean - diff_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.474439366197174\n"
     ]
    }
   ],
   "source": [
    "# 전체 평균 \n",
    "global_mean = df.lifeExp.mean() \n",
    "print(global_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "1952   -10.416820\n",
      "1957    -7.967038\n",
      "1962    -5.865190\n",
      "1967    -3.796150\n",
      "1972    -1.827053\n",
      "1977     0.095718\n",
      "1982     2.058758\n",
      "1987     3.738173\n",
      "1992     4.685899\n",
      "1997     5.540237\n",
      "2002     6.220483\n",
      "2007     7.532983\n",
      "Name: lifeExp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#전체 평균과 각각의 항목의 평균과 차이를 비교 \n",
    "agg_mean_diff = df.groupby('year').lifeExp.agg(my_mean_diff, diff_value=global_mean) \n",
    "print(agg_mean_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 집계 메서드를 리스트, 딕셔너리에 담아 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      count_nonzero       mean        std\n",
      "year                                     \n",
      "1952          142.0  49.057620  12.225956\n",
      "1957          142.0  51.507401  12.231286\n",
      "1962          142.0  53.609249  12.097245\n",
      "1967          142.0  55.678290  11.718858\n",
      "1972          142.0  57.647386  11.381953\n",
      "1977          142.0  59.570157  11.227229\n",
      "1982          142.0  61.533197  10.770618\n",
      "1987          142.0  63.212613  10.556285\n",
      "1992          142.0  64.160338  11.227380\n",
      "1997          142.0  65.014676  11.559439\n",
      "2002          142.0  65.694923  12.279823\n",
      "2007          142.0  67.007423  12.073021\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 데이터를 보낼 때 리스트를 이용하여 보낸다. \n",
    "import numpy as np\n",
    "gdf = df.groupby('year').lifeExp.agg([np.count_nonzero, np.mean, np.std]) \n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lifeExp         pop    gdpPercap\n",
      "year                                    \n",
      "1952  49.057620   556263527  1968.528344\n",
      "1957  51.507401   637408000  2173.220291\n",
      "1962  53.609249   665770000  2335.439533\n",
      "1967  55.678290   754550000  2678.334741\n",
      "1972  57.647386   862030000  3339.129407\n",
      "1977  59.570157   943455000  3798.609244\n",
      "1982  61.533197  1000281000  4216.228428\n",
      "1987  63.212613  1084035000  4280.300366\n",
      "1992  64.160338  1164970000  4386.085502\n",
      "1997  65.014676  1230075000  4781.825478\n",
      "2002  65.694923  1280400000  5319.804524\n",
      "2007  67.007423  1318683096  6124.371109\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 데이터를 보낼 때 딕셔너리를 이용하여 보낸다. \n",
    "gdf_dict = df.groupby('year').agg({'lifeExp': 'mean', 'pop': 'max', 'gdpPercap': 'median'}) \n",
    "print(gdf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datetime 오브젝트 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-03 15:11:18.637749\n"
     ]
    }
   ],
   "source": [
    "now1 = datetime.now() \n",
    "print(now1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-03 15:11:26.988781\n"
     ]
    }
   ],
   "source": [
    "now2 = datetime.today()\n",
    "print(now2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-03 15:12:15.055771\n",
      "1970-01-01 00:00:00\n",
      "1970-12-12 13:24:34\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.now() \n",
    "t2 = datetime(1970, 1, 1)\n",
    "t3 = datetime(1970, 12, 12, 13, 24, 34)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문자열을 datetime 오브젝트로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import os\n",
    "ebola = pd.read_csv('./data/country_timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122 entries, 0 to 121\n",
      "Data columns (total 18 columns):\n",
      "Date                   122 non-null object\n",
      "Day                    122 non-null int64\n",
      "Cases_Guinea           93 non-null float64\n",
      "Cases_Liberia          83 non-null float64\n",
      "Cases_SierraLeone      87 non-null float64\n",
      "Cases_Nigeria          38 non-null float64\n",
      "Cases_Senegal          25 non-null float64\n",
      "Cases_UnitedStates     18 non-null float64\n",
      "Cases_Spain            16 non-null float64\n",
      "Cases_Mali             12 non-null float64\n",
      "Deaths_Guinea          92 non-null float64\n",
      "Deaths_Liberia         81 non-null float64\n",
      "Deaths_SierraLeone     87 non-null float64\n",
      "Deaths_Nigeria         38 non-null float64\n",
      "Deaths_Senegal         22 non-null float64\n",
      "Deaths_UnitedStates    18 non-null float64\n",
      "Deaths_Spain           16 non-null float64\n",
      "Deaths_Mali            12 non-null float64\n",
      "dtypes: float64(16), int64(1), object(1)\n",
      "memory usage: 17.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ebola.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122 entries, 0 to 121\n",
      "Data columns (total 19 columns):\n",
      "Date                   122 non-null object\n",
      "Day                    122 non-null int64\n",
      "Cases_Guinea           93 non-null float64\n",
      "Cases_Liberia          83 non-null float64\n",
      "Cases_SierraLeone      87 non-null float64\n",
      "Cases_Nigeria          38 non-null float64\n",
      "Cases_Senegal          25 non-null float64\n",
      "Cases_UnitedStates     18 non-null float64\n",
      "Cases_Spain            16 non-null float64\n",
      "Cases_Mali             12 non-null float64\n",
      "Deaths_Guinea          92 non-null float64\n",
      "Deaths_Liberia         81 non-null float64\n",
      "Deaths_SierraLeone     87 non-null float64\n",
      "Deaths_Nigeria         38 non-null float64\n",
      "Deaths_Senegal         22 non-null float64\n",
      "Deaths_UnitedStates    18 non-null float64\n",
      "Deaths_Spain           16 non-null float64\n",
      "Deaths_Mali            12 non-null float64\n",
      "date_dt                122 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(16), int64(1), object(1)\n",
      "memory usage: 18.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ebola['date_dt'] = pd.to_datetime(ebola['Date'])\n",
    "print(ebola.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시계열 데이터를 구분해서 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-03 15:24:06.117785\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/02/03\n",
      "15:24:06\n",
      "2020-02-03 15:24:06\n"
     ]
    }
   ],
   "source": [
    "nowDate = now.strftime('%Y/%m/%d')\n",
    "print(nowDate)\n",
    "\n",
    "nowTime = now.strftime('%H:%M:%S')\n",
    "print(nowTime)\n",
    "\n",
    "nowDatetime = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(nowDatetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv를 읽을때 데이터를 어떤 형태로 받을지 확인 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122 entries, 0 to 121\n",
      "Data columns (total 18 columns):\n",
      "Date                   122 non-null datetime64[ns]\n",
      "Day                    122 non-null int64\n",
      "Cases_Guinea           93 non-null float64\n",
      "Cases_Liberia          83 non-null float64\n",
      "Cases_SierraLeone      87 non-null float64\n",
      "Cases_Nigeria          38 non-null float64\n",
      "Cases_Senegal          25 non-null float64\n",
      "Cases_UnitedStates     18 non-null float64\n",
      "Cases_Spain            16 non-null float64\n",
      "Cases_Mali             12 non-null float64\n",
      "Deaths_Guinea          92 non-null float64\n",
      "Deaths_Liberia         81 non-null float64\n",
      "Deaths_SierraLeone     87 non-null float64\n",
      "Deaths_Nigeria         38 non-null float64\n",
      "Deaths_Senegal         22 non-null float64\n",
      "Deaths_UnitedStates    18 non-null float64\n",
      "Deaths_Spain           16 non-null float64\n",
      "Deaths_Mali            12 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(16), int64(1)\n",
      "memory usage: 17.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ebola1 = pd.read_csv('./data/country_timeseries.csv', parse_dates=['Date']) \n",
    "print(ebola1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "##############################################\n",
    "### 행 방향과 열 방향으로 값들을 계산 ########\n",
    "###### 이거 해냈어! 끝이야! 난 섹시해! #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola1['Mean'] = ebola1.loc[:,['Cases_Guinea','Cases_SierraLeone','Cases_Liberia','Mean']].sum(axis=1,skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebola_subset = ebola1.loc[:,['Cases_Guinea','Cases_SierraLeone','Cases_Liberia','Mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Cases_Guinea  Cases_SierraLeone  Cases_Liberia     Mean\n",
      "0         2776.0            10030.0            NaN  38418.0\n",
      "1         2775.0             9780.0            NaN  37665.0\n",
      "2         2769.0             9722.0         8166.0  61971.0\n",
      "3            NaN                NaN         8157.0  24471.0\n",
      "4         2730.0             9633.0         8115.0  61434.0\n",
      "5         2706.0             9446.0         8018.0  60510.0\n",
      "6         2695.0             9409.0            NaN  36312.0\n",
      "7         2630.0             9203.0         7977.0  59430.0\n",
      "8         2597.0             9004.0            NaN  34803.0\n",
      "9         2571.0             8939.0         7862.0  58116.0\n",
      "10           NaN                NaN         7830.0  23490.0\n",
      "11        2416.0             8356.0            NaN  32316.0\n",
      "12           NaN                NaN         7797.0  23391.0\n",
      "13        2292.0             7897.0            NaN  30567.0\n",
      "14           NaN                NaN         7719.0  23157.0\n",
      "15        2164.0             7312.0            NaN  28428.0\n",
      "16           NaN                NaN         7635.0  22905.0\n",
      "17        2134.0             6599.0            NaN  26199.0\n",
      "18           NaN                NaN         7168.0  21504.0\n",
      "19        2047.0             6190.0         7082.0  45957.0\n",
      "Cases_Guinea           84729.0\n",
      "Cases_SierraLeone     211181.0\n",
      "Cases_Liberia         193833.0\n",
      "Mean                 1469229.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ebola_subset.head(n=20))\n",
    "print(ebola_subset.sum(skipna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
